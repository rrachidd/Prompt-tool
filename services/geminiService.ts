
import { GoogleGenAI, GenerateContentResponse, Modality, Type } from "@google/genai";

const API_KEY = process.env.API_KEY;

if (!API_KEY) {
  console.warn("API_KEY environment variable not set. Gemini API calls will fail.");
}

const ai = new GoogleGenAI({ apiKey: API_KEY! });

const handleApiError = (error: unknown, context: string): string => {
  console.error(`Error in ${context}:`, error);
  if (error instanceof Error) {
    return `An error occurred while ${context}: ${error.message}`;
  }
  return `An unknown error occurred while ${context}.`;
};

export interface AiNewsArticle {
  title: string;
  summary: string;
  sourceName: string;
  url: string;
  sourceTitle: string;
}

export const getAiNews = async (): Promise<AiNewsArticle[]> => {
  if (!API_KEY) {
    // Return dummy data if API key is not set
    return Promise.resolve([
      { title: 'Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠØºÙŠØ± Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù„Ø¹Ø¨Ø© ÙÙŠ Ø§Ù„Ø·Ø¨', summary: 'Ø§ÙƒØªØ´Ù ÙƒÙŠÙ ØªØ³Ø§Ù‡Ù… Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ ØªØ´Ø®ÙŠØµ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø¨Ø´ÙƒÙ„ Ø£Ø³Ø±Ø¹ ÙˆØ£ÙƒØ«Ø± Ø¯Ù‚Ø©.', sourceName: 'Tech News', url: '#', sourceTitle: 'Tech News Today' },
      { title: 'Ø¥Ø·Ù„Ø§Ù‚ Ù†Ù…ÙˆØ°Ø¬ Ù„ØºÙˆÙŠ Ø¬Ø¯ÙŠØ¯ ÙŠØªÙÙˆÙ‚ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†', summary: 'Ø£Ø¹Ù„Ù†Øª Ø´Ø±ÙƒØ© AI Corp Ø¹Ù† Ù†Ù…ÙˆØ°Ø¬Ù‡Ø§ Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ø°ÙŠ ÙŠÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…Ø³Ø¨ÙˆÙ‚.', sourceName: 'AI Weekly', url: '#', sourceTitle: 'AI Weekly Insights' },
      { title: 'Ù…Ø®Ø§ÙˆÙ Ø£Ø®Ù„Ø§Ù‚ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© ØªØ­ÙŠØ· Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠ', summary: 'Ø®Ø¨Ø±Ø§Ø¡ ÙŠØ¯Ø¹ÙˆÙ† Ø¥Ù„Ù‰ ØªÙ†Ø¸ÙŠÙ…Ø§Øª Ø£Ø´Ø¯ ØµØ±Ø§Ù…Ø© Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø³Ø¤ÙˆÙ„ Ù„Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§.', sourceName: 'Future Tech', url: '#', sourceTitle: 'Future of Technology' },
      { title: 'Ø§Ù„ÙÙ† ÙˆØ§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ: Ø¥Ø¨Ø¯Ø§Ø¹ Ø£Ù… ØªÙ‚Ù„ÙŠØ¯ØŸ', summary: 'Ù†Ù‚Ø§Ø´ Ø­Ø§Ø¯ ÙÙŠ Ø§Ù„Ø£ÙˆØ³Ø§Ø· Ø§Ù„ÙÙ†ÙŠØ© Ø­ÙˆÙ„ Ø¯ÙˆØ± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹.', sourceName: 'Creative World', url: '#', sourceTitle: 'Creative World Magazine' },
      { title: 'ÙƒÙŠÙ Ø³ÙŠØ¤Ø«Ø± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ù„Ù‰ Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø­Ù„ÙˆÙ„ 2030', summary: 'ØªÙ‚Ø±ÙŠØ± Ø¬Ø¯ÙŠØ¯ ÙŠØªÙˆÙ‚Ø¹ ØªØ­ÙˆÙ„Ø§Øª Ø¬Ø°Ø±ÙŠØ© ÙÙŠ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙˆÙŠØ¯Ø¹Ùˆ Ø¥Ù„Ù‰ Ø¥Ø¹Ø§Ø¯Ø© ØªØ£Ù‡ÙŠÙ„ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª.', sourceName: 'Economics Today', url: '#', sourceTitle: 'Economics Today Report' },
      { title: 'Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª Ù…Ø¯Ù‡Ø´Ø© Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„ÙØ¶Ø§Ø¡', summary: 'Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ„Ø³ÙƒÙˆØ¨Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª Ø§Ù„ÙØ¶Ø§Ø¦ÙŠØ©ØŒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙØªØ­ Ø¢ÙØ§Ù‚Ù‹Ø§ Ø¬Ø¯ÙŠØ¯Ø©.', sourceName: 'Space Journal', url: '#', sourceTitle: 'The Space Journal' },
    ]);
  }
  try {
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: `You are an AI news aggregator. Find the top 6 latest and most important news articles in Arabic about Artificial Intelligence from the past week. 
      For each article, provide a concise title, a brief summary (2-3 sentences), and the primary source name.
      Format the output as a JSON array of objects, where each object has "title", "summary", and "sourceName" keys.
      Respond with ONLY the JSON array, without any markdown formatting or extra text.`,
      config: {
        tools: [{ googleSearch: {} }],
        temperature: 0.2,
      },
    });

    const groundingChunks = response.candidates?.[0]?.groundingMetadata?.groundingChunks;
    const urls = groundingChunks?.map(chunk => ({ uri: chunk.web?.uri || '#', title: chunk.web?.title || '' })) || [];
    
    // Clean the response: remove markdown fences and trim whitespace.
    const jsonText = response.text.trim().replace(/^```json\s*/, '').replace(/```$/, '');
    const articlesFromAI = JSON.parse(jsonText);

    if (!Array.isArray(articlesFromAI)) {
      throw new Error("AI response is not a JSON array.");
    }
    
    // Merge AI-generated content with grounded URLs
    const mergedArticles: AiNewsArticle[] = articlesFromAI.slice(0, 6).map((article, index) => ({
      title: article.title || 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù†ÙˆØ§Ù†',
      summary: article.summary || 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ø®Øµ',
      sourceName: article.sourceName || (urls[index]?.title ? new URL(urls[index].uri).hostname : 'Ù…ØµØ¯Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'),
      url: urls[index]?.uri || '#', // Associate by index, a best-effort approach
      sourceTitle: urls[index]?.title || article.sourceName || 'Ù…ØµØ¯Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ',
    }));

    return mergedArticles;

  } catch (error) {
    console.error("Error fetching AI news:", error);
    const errorMessage = handleApiError(error, "fetching AI news");
    throw new Error(errorMessage);
  }
};


export const generatePrompt = async (topic: string): Promise<string> => {
  if (!API_KEY) {
    return Promise.resolve(`API Key not configured. For now, here is a dummy prompt for "${topic}".
    
    **Example Prompt:**
    Generate a detailed and vivid description of a futuristic cityscape at sunset. Include details about the architecture, transportation, and the overall atmosphere. The tone should be awe-inspiring and slightly melancholic.`);
  }

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: `You are a creative assistant specialized in generating high-quality prompts for AI models.
      Based on the following topic, create a detailed and effective prompt that can be used to generate text or images.
      The prompt should be clear, specific, and provide enough context for an AI to produce a great result.

      Topic: "${topic}"
      
      Generated Prompt:`,
       config: {
        temperature: 0.7,
        topP: 0.95,
      }
    });
    return response.text;
  } catch (error) {
    return handleApiError(error, "generating the prompt");
  }
};

export const generatePromptFromImage = async (mimeType: string, imageBase64: string): Promise<string> => {
   if (!API_KEY) {
    return Promise.resolve(`API Key not configured. This is a dummy description for the uploaded image.`);
  }
  try {
    const imagePart = {
      inlineData: {
        mimeType,
        data: imageBase64,
      },
    };
    const textPart = {
      text: "Describe this image in detail. What objects are present, what is the style (e.g., photorealistic, cartoon, watercolor), what are the dominant colors, what is the lighting like, and what is the overall composition? This description will be used as a prompt for an image generation AI."
    };
    
    const response: GenerateContentResponse = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: { parts: [imagePart, textPart] },
    });
    
    return response.text;
  } catch (error) {
    return handleApiError(error, "generating prompt from image");
  }
};

export const generateVideoScript = async (topic: string): Promise<string> => {
  if (!API_KEY) {
    return Promise.resolve(`API Key not configured. Here is a dummy script for a video about "${topic}".

**Title:** The Ultimate Guide to ${topic}

**Script:**
**(Intro Music)**
**Host:** Hello and welcome back to our channel! Today, we're diving deep into the world of ${topic}.
...
**(Outro Music)**
`);
  }
  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: `You are an expert YouTube scriptwriter. Your task is to generate a catchy title and a complete video script based on the provided topic.
      The script should be engaging and well-structured, including:
      1.  An introduction to hook the viewer.
      2.  Main content broken down into clear sections.
      3.  A conclusion that summarizes the key points and includes a call to action (e.g., "like, share, and subscribe").
      
      Format the output clearly with a "Title:" section and a "Script:" section.
      
      Topic: "${topic}"
      `,
      config: {
        temperature: 0.8,
        topP: 0.95,
      }
    });
    return response.text;
  } catch (error) {
    return handleApiError(error, "generating video script");
  }
};

export const generateYoutubeTitles = async (topic: string): Promise<string[]> => {
    if (!API_KEY) {
        return Array.from({ length: 10 }, (_, i) => `Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‚ØªØ±Ø­ Ø±Ù‚Ù… ${i + 1} Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹: "${topic}" (Ù…ÙØªØ§Ø­ API ØºÙŠØ± Ù…ØªÙˆÙØ±)`);
    }
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: `You are an expert YouTube title creator. Your task is to generate 10 compelling and clickable video titles in Arabic based on the provided topic.

            Each title must follow these critical rules:
            1.  **Clarity First:** The title must clearly state what the video is about.
            2.  **Arouse Curiosity:** Use questions or promise a result to make people want to click, but do not be misleading (no clickbait).
            3.  **Use Keywords:** Include keywords that people would search for in Arabic.
            4.  **Ideal Length:** Keep titles between 50 and 65 characters.
            5.  **Unique Value:** Highlight what makes the video special (e.g., "Ø£Ø³Ù‡Ù„ Ø·Ø±ÙŠÙ‚Ø©", "Ø§Ù„Ø³Ø± Ø§Ù„Ø°ÙŠ Ù„Ù… ÙŠØ®Ø¨Ø±Ùƒ Ø¨Ù‡ Ø£Ø­Ø¯").
            6.  **Use Numbers/Dates:** Incorporate numbers, lists, or a relevant year (e.g., 2025) to grab attention.
            7.  **Thumbnail Harmony:** Create titles that would work well with a visual thumbnail (e.g., a title poses a question, the thumbnail shows the result).

            Topic: "${topic}"
            `,
            config: {
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.OBJECT,
                    properties: {
                        titles: {
                            type: Type.ARRAY,
                            items: {
                                type: Type.STRING,
                                description: 'A compelling YouTube video title in Arabic.'
                            },
                            description: 'An array of 10 generated YouTube titles.'
                        }
                    },
                    required: ["titles"],
                }
            }
        });

        // Clean the response: remove markdown fences and trim whitespace.
        const jsonText = response.text.trim().replace(/^```json\s*/, '').replace(/```$/, '');
        const result = JSON.parse(jsonText);

        if (result && Array.isArray(result.titles)) {
            // Ensure all items in the array are strings before returning.
            // This prevents rendering [object Object] in React if the API returns an array of objects.
            return result.titles.filter((item: unknown) => typeof item === 'string');
        }

        throw new Error("The API returned an unexpected format for YouTube titles.");

    } catch (error) {
        const errorMessage = handleApiError(error, "generating YouTube titles");
        throw new Error(errorMessage);
    }
};

export const generateYoutubeDescription = async (videoTitle: string): Promise<string> => {
  if (!API_KEY) {
    return Promise.resolve(`API Key not configured. Here is a dummy description for a video titled "${videoTitle}".`);
  }
  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: `You are a YouTube SEO and content expert. Your task is to write a comprehensive and engaging video description in Arabic based on the provided video title. The description must be structured perfectly to attract viewers and satisfy the YouTube algorithm.

      Follow these rules strictly:
      1.  **First Two Lines:** Start with 1-2 compelling sentences that summarize the video's core value and include the most important keywords from the title. This is what appears in search results.
      2.  **SEO Keywords:** Naturally integrate keywords related to the title throughout the description, especially in the first paragraph. Do not stuff keywords unnaturally.
      3.  **Value Summary:** After the initial hook, write a short paragraph (2-3 sentences) explaining what the viewer will learn or gain from watching the video.
      4.  **Timestamps (Chapters):** Include a list of timestamps with descriptive titles. This is crucial for user experience. Create logical chapters based on the likely structure of a video with this title.
          Example format:
          00:00 Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©
          01:15 Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
          03:40 Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©
          ...
      5.  **Useful Links & CTA:** Add a section for useful links. Include placeholders for social media and a clear Call to Action (CTA) encouraging viewers to subscribe and watch another video.
          Example format:
          
          ---
          
          ğŸ”— Ø±ÙˆØ§Ø¨Ø· Ù…ÙÙŠØ¯Ø©:
          Ø´Ø§Ù‡Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø³Ø§Ø¨Ù‚: [Ø¶Ø¹ Ø§Ù„Ø±Ø§Ø¨Ø· Ù‡Ù†Ø§]
          ØªØ§Ø¨Ø¹Ù†Ø§ Ø¹Ù„Ù‰ Ø§Ù†Ø³ØªØºØ±Ø§Ù…: [Ø¶Ø¹ Ø§Ù„Ø±Ø§Ø¨Ø· Ù‡Ù†Ø§]
          
          Ù„Ø§ ØªÙ†Ø³Ù Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ ÙÙŠ Ø§Ù„Ù‚Ù†Ø§Ø© ÙˆØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¬Ø±Ø³ Ù„ÙŠØµÙ„Ùƒ ÙƒÙ„ Ø¬Ø¯ÙŠØ¯!
      6.  **Hashtags:** Conclude with 3 to 5 highly relevant hashtags.

      **Video Title:** "${videoTitle}"
      `,
       config: {
        temperature: 0.7,
        topP: 0.95,
      }
    });
    return response.text;
  } catch (error) {
    return handleApiError(error, "generating YouTube description");
  }
};


export const checkPromptQuality = async (prompt: string): Promise<string> => {
  if (!API_KEY) {
    return Promise.resolve(`API Key not configured. Prompt quality check is unavailable.`);
  }
  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: `You are a prompt engineering expert. Analyze the following prompt for its quality and effectiveness for an AI image or text generation model.
      Provide a concise evaluation covering clarity, specificity, and creative potential.
      Then, offer concrete suggestions for improvement. Format your response clearly with sections for "Evaluation" and "Suggestions".

      Prompt: "${prompt}"
      `,
    });
    return response.text;
  } catch (error) {
    return handleApiError(error, "checking prompt quality");
  }
};

export const detectAiText = async (text: string): Promise<string> => {
  if (!API_KEY) {
    return Promise.resolve(`API Key not configured. AI detection is unavailable.`);
  }
  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: `Analyze the following text and determine the likelihood that it was generated by an AI.
      Provide a percentage likelihood and a brief justification for your analysis, pointing out any specific patterns, phrasing, or characteristics that support your conclusion.

      Text: "${text}"
      `,
    });
    return response.text;
  } catch (error) {
    return handleApiError(error, "detecting AI text");
  }
};

export const rephraseText = async (text: string): Promise<string> => {
  if (!API_KEY) {
    return Promise.resolve(`API Key not configured. Rephrasing is unavailable.`);
  }
  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: `Rewrite the following text to make it sound more natural, engaging, and human-like.
      Preserve the core meaning but improve the tone, flow, and word choice. Avoid jargon and overly formal language unless it's essential to the context.

      Original Text: "${text}"

      Rephrased Text:
      `,
    });
    return response.text;
  } catch (error) {
    return handleApiError(error, "rephrasing text");
  }
};


export const imageFusionPrompt = async (
  image1: { mimeType: string; imageBase64: string },
  image2: { mimeType: string; imageBase64: string }
): Promise<string> => {
  if (!API_KEY) {
    return Promise.resolve(`API Key not configured. Image fusion is unavailable.`);
  }
  try {
    const imagePart1 = { inlineData: { mimeType: image1.mimeType, data: image1.imageBase64 } };
    const imagePart2 = { inlineData: { mimeType: image2.mimeType, data: image2.imageBase64 } };
    const textPart = {
      text: "You are an expert in creating prompts for AI image generation models. Analyze these two images. Create a single, detailed text prompt that creatively combines the key subjects, styles, colors, and concepts from both images. The goal is to generate a new, unique image that is a fusion of the two. Describe the desired composition, lighting, and artistic style clearly."
    };

    const response: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-2.5-flash',
      contents: { parts: [textPart, imagePart1, imagePart2] },
    });

    return response.text;
  } catch (error) {
    return handleApiError(error, "fusing images into a prompt");
  }
};

export const removeImageBackground = async (mimeType: string, imageBase64: string): Promise<{ base64: string, mimeType: string }> => {
  if (!API_KEY) {
    throw new Error("API Key not configured. Background removal is unavailable.");
  }
  try {
    const imagePart = {
      inlineData: {
        mimeType,
        data: imageBase64,
      },
    };
    const textPart = {
      text: "Remove the background from this image. The new background should be transparent. Output only the resulting image with a transparent background."
    };

    const response: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: { parts: [imagePart, textPart] },
      // FIX: The `responseModalities` for `gemini-2.5-flash-image` must be an array with a single `Modality.IMAGE` element.
      config: {
          responseModalities: [Modality.IMAGE],
      },
    });

    for (const part of response.candidates[0].content.parts) {
      if (part.inlineData && part.inlineData.mimeType.startsWith('image/')) {
        return { base64: part.inlineData.data, mimeType: part.inlineData.mimeType };
      }
    }
    
    const textResponse = response.text?.trim();
    if (textResponse) {
        throw new Error(`API returned a text response instead of an image: "${textResponse}"`);
    }

    throw new Error("The API did not return an image. It might have refused the request due to safety policies.");

  } catch (error) {
     console.error(`Error in removing image background:`, error);
     if (error instanceof Error) {
        throw new Error(`An error occurred while removing image background: ${error.message}`);
     }
     throw new Error(`An unknown error occurred while removing image background.`);
  }
};

export const extractTextFromImage = async (mimeType: string, imageBase64: string): Promise<string> => {
  if (!API_KEY) {
    return Promise.resolve(`API Key not configured. OCR is unavailable.`);
  }
  try {
    const imagePart = {
      inlineData: {
        mimeType,
        data: imageBase64,
      },
    };
    const textPart = {
      text: "Perform OCR on this image. Extract all text content accurately. Preserve the original line breaks and formatting as much as possible. If there is no text, respond with 'No text found in the image.'."
    };
    
    const response: GenerateContentResponse = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: { parts: [imagePart, textPart] },
    });
    
    return response.text;
  } catch (error) {
    return handleApiError(error, "extracting text from image (OCR)");
  }
};

export const readBarcodeFromImage = async (mimeType: string, imageBase64: string): Promise<string> => {
  if (!API_KEY) {
    return Promise.resolve(`API Key not configured. Barcode reading is unavailable.`);
  }
  try {
    const imagePart = {
      inlineData: {
        mimeType,
        data: imageBase64,
      },
    };
    const textPart = {
      text: "Analyze this image. If it contains a barcode or a QR code, decode it and return only the raw data it contains (e.g., a URL or plain text). Do not add any extra explanation. If no barcode or QR code is found, return the string 'No barcode or QR code found.'."
    };
    
    const response: GenerateContentResponse = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: { parts: [imagePart, textPart] },
    });
    
    return response.text;
  } catch (error) {
    return handleApiError(error, "reading barcode from image");
  }
};

export const restoreAndColorizePhoto = async (mimeType: string, imageBase64: string): Promise<{ base64: string, mimeType: string }> => {
  if (!API_KEY) {
    throw new Error("API Key not configured. Photo restoration is unavailable.");
  }
  try {
    const imagePart = {
      inlineData: {
        mimeType,
        data: imageBase64,
      },
    };
    const textPart = {
      text: "Restore this old, heavily damaged photo by removing all visible scratches, dents, folds, and stains. Reconstruct missing or distorted facial features naturally and realistically while preserving the original identity and expressions of the person. Maintain the authentic vintage look, but enhance clarity, sharpness, and detail to look like a high-quality modern photo. If the photo is black and white, convert it to realistic color based on skin tone, hair, eyes, and background elements, ensuring the result looks natural and historically appropriate."
    };

    const response: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: { parts: [imagePart, textPart] },
      // FIX: The `responseModalities` for `gemini-2.5-flash-image` must be an array with a single `Modality.IMAGE` element.
      config: {
          responseModalities: [Modality.IMAGE],
      },
    });

    for (const part of response.candidates[0].content.parts) {
      if (part.inlineData && part.inlineData.mimeType.startsWith('image/')) {
        return { base64: part.inlineData.data, mimeType: part.inlineData.mimeType };
      }
    }
    
    const textResponse = response.text?.trim();
    if (textResponse) {
        throw new Error(`API returned a text response instead of an image: "${textResponse}"`);
    }

    throw new Error("The API did not return an image. It might have refused the request due to safety policies.");

  } catch (error) {
     console.error(`Error in restoring and colorizing photo:`, error);
     if (error instanceof Error) {
        throw new Error(`An error occurred while restoring and colorizing photo: ${error.message}`);
     }
     throw new Error(`An unknown error occurred while restoring and colorizing photo.`);
  }
};

export const mergePhotos = async (
  groupImage: { mimeType: string; imageBase64: string },
  personImage: { mimeType: string; imageBase64: string },
  groupDescription: string,
  personDescription: string
): Promise<{ base64: string, mimeType: string }> => {
  if (!API_KEY) {
    throw new Error("API Key not configured. Photo merging is unavailable.");
  }
  try {
    const groupImagePart = { inlineData: { mimeType: groupImage.mimeType, data: groupImage.imageBase64 } };
    const personImagePart = { inlineData: { mimeType: personImage.mimeType, data: personImage.imageBase64 } };
    
    const textPrompt = `Merge two separate photos into one (a single, high-quality picture). The first photo is of: ${groupDescription}, and the second is of ${personDescription}. Naturally place the person from the second photo into the first photo, making sure all facial expressions, lighting, skin tones, and clothing details are preserved to look authentic. Ensure the smile appears warm and genuine, and the overall image radiates love, joy, and emotional connection. Maintain the original look, posture, and identity of each person. Blend backgrounds seamlessly or use a soft, neutral background that enhances the focus on the group. The final image should look like a professionally captured real photo, not edited or artificial.`;

    const response: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: { parts: [groupImagePart, personImagePart, { text: textPrompt }] },
      // FIX: The `responseModalities` for `gemini-2.5-flash-image` must be an array with a single `Modality.IMAGE` element.
      config: {
          responseModalities: [Modality.IMAGE],
      },
    });

    for (const part of response.candidates[0].content.parts) {
      if (part.inlineData && part.inlineData.mimeType.startsWith('image/')) {
        return { base64: part.inlineData.data, mimeType: part.inlineData.mimeType };
      }
    }
    
    const textResponse = response.text?.trim();
    if (textResponse) {
        throw new Error(`API returned a text response instead of an image: "${textResponse}"`);
    }

    throw new Error("The API did not return an image. It might have refused the request due to safety policies.");

  } catch (error) {
     console.error(`Error in merging photos:`, error);
     if (error instanceof Error) {
        throw new Error(`An error occurred while merging photos: ${error.message}`);
     }
     throw new Error(`An unknown error occurred while merging photos.`);
  }
};

export interface VideoPromptOptions {
    mainScene: string;
    mainSubject: string;
    mood: string;
    lighting: string;
    openingShot: string;
    cameraMotions: string;
    secondaryElements: string;
    dof: string;
    dynamicElements: string;
    warmLight: string;
    coolLight: string;
    colorScheme: string;
    music: string;
    sfx: string;
    ending: string;
}

export const generateShortVideo = async (options: VideoPromptOptions, onProgress?: (message: string) => void): Promise<string> => {
    if (!API_KEY) {
        throw new Error("API Key not configured. Video generation is unavailable.");
    }

    const prompt = `A 30-second cinematic, ultra-realistic video in 16:9 aspect ratio.
Scene: ${options.mainScene}.
Subject: ${options.mainSubject}.
Mood: ${options.mood}.
Lighting: ${options.lighting}, with dramatic contrast between ${options.warmLight} and ${options.coolLight}. Include realistic reflections, shadows, and caustic light behavior.
Camera: Starts with ${options.openingShot}, and smoothly transitions through motions like ${options.cameraMotions}. Use a ${options.dof} for focus.
Visual Effects: The subject is surrounded by ${options.secondaryElements}. The environment has subtle dynamic elements like ${options.dynamicElements}.
Color Palette: ${options.colorScheme}.
Important: No distracting elements, text, or logos. No human faces unless described.
Audio: The background music should be ${options.music}, with sound effects like ${options.sfx}.
Ending: The final shot fades out slowly on ${options.ending}.
Overall Tone: The video must be ultra high resolution, with realistic detail, professional composition, and a luxurious tone.`;

    try {
        onProgress?.('ğŸš€ Starting video generation...');
        let operation = await ai.models.generateVideos({
            model: 'veo-3.1-fast-generate-preview',
            prompt: prompt,
            config: {
                numberOfVideos: 1
            }
        });
        
        onProgress?.('â³ Processing request... this may take several minutes.');
        let checks = 0;
        const progressMessages = [
            'ğŸ¨ Composing scenes...',
            'ğŸ¬ Rendering frames...',
            'ğŸ”Š Syncing audio...',
            'âœ¨ Applying final touches...'
        ];

        while (!operation.done) {
            await new Promise(resolve => setTimeout(resolve, 10000)); // Poll every 10 seconds
            const message = progressMessages[checks % progressMessages.length];
            onProgress?.(`â³ ${message}`);
            operation = await ai.operations.getVideosOperation({ operation: operation });
            checks++;
        }
        
        onProgress?.('âœ… Finalizing video...');
        const downloadLink = operation.response?.generatedVideos?.[0]?.video?.uri;

        if (!downloadLink) {
            throw new Error("Video generation completed, but no download link was provided by the API.");
        }

        onProgress?.('â¬‡ï¸ Downloading generated video...');
        const response = await fetch(`${downloadLink}&key=${API_KEY}`);
        
        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`Failed to download video. Status: ${response.status}. Message: ${errorText}`);
        }

        const videoBlob = await response.blob();
        const videoUrl = URL.createObjectURL(videoBlob);
        
        onProgress?.(''); // Clear message
        return videoUrl;

    } catch (error) {
        console.error("Error generating short video:", error);
        const errorMessage = handleApiError(error, "generating short video");
        throw new Error(errorMessage);
    }
};

export interface ArticleGenerationParams {
  title: string;
  keyword: string;
  description: string;
  category: string;
  tone: string;
  length: 'short' | 'medium' | 'long' | 'very-long';
  intent: string;
  audience: string;
  additionalInfo?: string;
}

export const generateProfessionalArticle = async (params: ArticleGenerationParams): Promise<any> => {
  if (!API_KEY) {
    throw new Error("API Key not configured. Article generation is unavailable.");
  }

  const lengthInWords = {
    short: '300-500 words',
    medium: '500-800 words',
    long: '800-1200 words',
    'very-long': '1200+ words',
  }[params.length] || '500-800 words';

  const prompt = `Based on the following parameters, generate a comprehensive, unique, and SEO-optimized article in Arabic. The article must be well-structured with headings (h2, h3), paragraphs (p), and lists (ul/ol).

Parameters:
- Article Title: ${params.title}
- Main Keyword: ${params.keyword}
- Brief Description: ${params.description}
- Category: ${params.category}
- Tone of Voice: ${params.tone}
- Desired Length: ${lengthInWords}
- Search Intent: ${params.intent}
- Target Audience: ${params.audience}
- Additional Info: ${params.additionalInfo || 'None'}

Please provide the output in a structured JSON format. The htmlContent should be a single string of well-formed HTML.
`;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-pro',
      contents: prompt,
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            generatedTitle: { type: Type.STRING, description: 'The final, SEO-optimized title of the article.' },
            htmlContent: { type: Type.STRING, description: 'The full article content as a single HTML string, including h2, h3, p, ul, ol, and li tags.' },
            metaDescription: { type: Type.STRING, description: 'A compelling meta description between 150-160 characters.' },
            urlSlug: { type: Type.STRING, description: 'A short, URL-friendly slug in Arabic.' },
            suggestedKeywords: {
              type: Type.ARRAY,
              items: { type: Type.STRING },
              description: 'An array of 5-7 related LSI keywords.'
            },
            wordCount: { type: Type.INTEGER, description: 'The total word count of the generated article.' }
          },
          required: ["generatedTitle", "htmlContent", "metaDescription", "urlSlug", "suggestedKeywords", "wordCount"]
        }
      }
    });

    const jsonText = response.text.trim();
    const articleData = JSON.parse(jsonText);
    
    // Add some calculated metrics
    const keywordRegex = new RegExp(params.keyword, 'gi');
    const keywordMatches = (articleData.htmlContent.match(keywordRegex) || []).length;
    articleData.keywordDensity = articleData.wordCount > 0 ? ((keywordMatches / articleData.wordCount) * 100).toFixed(2) : '0.00';
    articleData.readingTime = Math.ceil(articleData.wordCount / 200);

    return articleData;

  } catch (error) {
    const errorMessage = handleApiError(error, "generating professional article");
    throw new Error(errorMessage);
  }
};

export interface VideoTranscriptResult {
    title: string;
    description: string;
    transcript: string;
}

export const transcribeYoutubeVideo = async (url: string, language: string): Promise<VideoTranscriptResult> => {
    if (!API_KEY) {
        return Promise.resolve({
            title: 'Ø¹Ù†ÙˆØ§Ù† ÙÙŠØ¯ÙŠÙˆ ØªØ¬Ø±ÙŠØ¨ÙŠ',
            description: 'Ù‡Ø°Ø§ ÙˆØµÙ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù„Ø£Ù† Ù…ÙØªØ§Ø­ API ØºÙŠØ± Ù…Ù‡ÙŠØ£.',
            transcript: `Ù‡Ø°Ø§ Ù†Øµ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù…ØªØ±Ø¬Ù… Ø¥Ù„Ù‰ ${language}.`
        });
    }

    try {
        const languageName = new Intl.DisplayNames(['ar'], { type: 'language' }).of(language) || language;

        const response = await ai.models.generateContent({
            model: "gemini-2.5-pro",
            contents: `1. Use the website youtubetranscript.com to find and extract the full transcript for the YouTube video at this URL: ${url}.
2. From the YouTube page itself, get the original title and description of the video.
3. Translate the entire transcript you found in step 1 into the language: "${languageName}".

Respond ONLY with a JSON object containing three keys: "title", "description", and "transcript".
- "title" should be the video's original title.
- "description" should be the video's original description.
- "transcript" should be the translated text.
If a transcript cannot be found, the "transcript" value should be a message indicating that, but still return the title and description if available.`,
            config: {
                tools: [{ googleSearch: {} }],
            },
        });
        
        const text = response.text;
        if (!text || typeof text !== 'string') {
            throw new Error("Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ù† ØªÙˆÙ„ÙŠØ¯ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù†ØµÙŠØ©. Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ø¨Ø³Ø¨Ø¨ Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø£Ùˆ Ø¹Ø¯Ù… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.");
        }

        const jsonText = text.trim().replace(/^```json\s*/, '').replace(/```$/, '');
        
        if (!jsonText) {
             throw new Error("Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙƒØ§Ù†Øª ÙØ§Ø±ØºØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ.");
        }

        const resultJson = JSON.parse(jsonText);

        return {
            title: resultJson.title || 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù†ÙˆØ§Ù†',
            description: resultJson.description || 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØµÙ',
            transcript: resultJson.transcript || 'Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ Ù„Ù„ÙÙŠØ¯ÙŠÙˆ Ø£Ùˆ ØªØ±Ø¬Ù…ØªÙ‡.',
        };

    } catch (error) {
        console.error("Error in transcribeYoutubeVideo:", error);
        
        if (error instanceof SyntaxError) { // This handles JSON.parse errors
            const userFriendlyError = 'ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ØºÙŠØ± ØµØ­ÙŠØ­. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.';
            throw new Error(userFriendlyError);
        }

        if (error instanceof Error && error.message.includes("Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")) {
            throw error; // re-throw our custom error
        }
        
        const userFriendlyError = 'ÙØ´Ù„ ÙÙŠ ØªÙØ±ÙŠØº Ø§Ù„ÙÙŠØ¯ÙŠÙˆ. Ù‚Ø¯ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¹Ù„Ù‰ Ù†Øµ Ø£Ùˆ ØªØ±Ø¬Ù…Ø© Ù…ØªØ§Ø­Ø©ØŒ Ø£Ùˆ Ù‚Ø¯ ØªÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ Ù…Ø´ÙƒÙ„Ø© Ù…Ø¤Ù‚ØªØ© ÙÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©. ÙŠØ±Ø¬Ù‰ Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙŠØ¯ÙŠÙˆ Ø¢Ø®Ø±.';
        throw new Error(userFriendlyError);
    }
};
